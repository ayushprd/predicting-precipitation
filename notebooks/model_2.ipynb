{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from geopy.distance import great_circle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score, cross_val_predict, LeaveOneOut\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, accuracy_score, precision_score, recall_score, f1_score, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/GHCND_data.csv')\n",
    "\n",
    "data['DATE'] = pd.to_datetime(data['DATE'])\n",
    "\n",
    "columns_to_drop = ['TAVG'] \n",
    "data = data.drop(columns=columns_to_drop)\n",
    "\n",
    "data = data.sort_values(by=['STATION', 'DATE'])\n",
    "\n",
    "# Extract month from the DATE\n",
    "data['MONTH'] = data['DATE'].dt.month\n",
    "\n",
    "# Seasonal Features\n",
    "data['MONTH_SIN'] = np.sin(2 * np.pi * data['MONTH'] / 12)\n",
    "data['MONTH_COS'] = np.cos(2 * np.pi * data['MONTH'] / 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating 3 day lags of PRCP, TMAX and TMIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lag features for the current station\n",
    "for lag in range(1, 3):\n",
    "    data[f'PRCP_LAG_{lag}'] = data.groupby('STATION')['PRCP'].shift(lag)\n",
    "    data[f'TMAX_LAG_{lag}'] = data.groupby('STATION')['TMAX'].shift(lag)\n",
    "    data[f'TMIN_LAG_{lag}'] = data.groupby('STATION')['TMIN'].shift(lag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the nearest 3 stations for each station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique stations with their coordinates\n",
    "stations = data[['STATION', 'LATITUDE', 'LONGITUDE']].drop_duplicates()\n",
    "\n",
    "# Function to calculate the distance between two coordinates\n",
    "def calculate_distance(coord1, coord2):\n",
    "    return great_circle(coord1, coord2).km\n",
    "\n",
    "# Create a dictionary to store the three closest neighbors for each station\n",
    "station_nearby = {}\n",
    "\n",
    "# Calculate distances and store the three closest neighbors for each station\n",
    "for i, row1 in stations.iterrows():\n",
    "    distances = []\n",
    "    for j, row2 in stations.iterrows():\n",
    "        if i != j:\n",
    "            coord1 = (row1['LATITUDE'], row1['LONGITUDE'])\n",
    "            coord2 = (row2['LATITUDE'], row2['LONGITUDE'])\n",
    "            distance = calculate_distance(coord1, coord2)\n",
    "            distances.append((row2['STATION'], distance))\n",
    "    # Sort by distance and take the three closest neighbors\n",
    "    distances = sorted(distances, key=lambda x: x[1])[:3]\n",
    "    station_nearby[row1['STATION']] = [neighbor[0] for neighbor in distances]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now adding 3 day lags of precipiatationa and temperature of these nearest 3 stations for each station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbor_lag_features = pd.DataFrame()\n",
    "\n",
    "# Create lag features for the three closest neighbors\n",
    "for station, nearby_stations in station_nearby.items():\n",
    "    station_data = data[data['STATION'] == station].copy()\n",
    "    for i, nearby_station in enumerate(nearby_stations):\n",
    "        for lag in range(1, 3):\n",
    "            # Create lagged features for the neighboring station\n",
    "            lagged_cols = data[data['STATION'] == nearby_station][['DATE', 'PRCP', 'TMAX', 'TMIN']].copy()\n",
    "            lagged_cols['DATE'] = lagged_cols['DATE'] + pd.Timedelta(days=lag)\n",
    "            lagged_cols = lagged_cols.rename(columns={'PRCP': f'NEIGHBOR_{i+1}_PRCP_LAG_{lag}',\n",
    "                                                      'TMAX': f'NEIGHBOR_{i+1}_TMAX_LAG_{lag}',\n",
    "                                                      'TMIN': f'NEIGHBOR_{i+1}_TMIN_LAG_{lag}'})\n",
    "            station_data = pd.merge(station_data, lagged_cols, on='DATE', how='left')\n",
    "    neighbor_lag_features = pd.concat([neighbor_lag_features, station_data], axis=0)\n",
    "\n",
    "neighbor_lag_features = neighbor_lag_features.loc[:, ~neighbor_lag_features.columns.duplicated()]\n",
    "neighbor_lag_features = neighbor_lag_features.dropna()\n",
    "\n",
    "data = neighbor_lag_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation 1: Using fixed train, test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the STATION column\n",
    "data = pd.get_dummies(data, columns=['STATION'], drop_first=True)\n",
    "\n",
    "# Define the test set period\n",
    "test_period_start = '2023-01-01'\n",
    "\n",
    "# Split the data into training and test sets based on the DATE\n",
    "train_data = data[data['DATE'] < test_period_start]\n",
    "test_data = data[data['DATE'] >= test_period_start]\n",
    "\n",
    "# Define features and target variable\n",
    "features = train_data.drop(columns=['NAME', 'LATITUDE', 'LONGITUDE', 'ELEVATION', 'DATE', 'PRCP'])\n",
    "target = train_data['PRCP']\n",
    "\n",
    "# Define the same for the test data\n",
    "test_features = test_data.drop(columns=['NAME', 'LATITUDE', 'LONGITUDE', 'ELEVATION', 'DATE', 'PRCP'])\n",
    "test_target = test_data['PRCP']\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "test_features_scaled = scaler.transform(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_503909/954747429.py:18: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
      "  torch.tensor([seq for seq, label in train_sequences], dtype=torch.float32),\n"
     ]
    }
   ],
   "source": [
    "# Convert data to sequences for LSTM\n",
    "def create_sequences(data, target, sequence_length):\n",
    "    sequences = []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        seq = data[i:i+sequence_length]\n",
    "        label = target[i+sequence_length]\n",
    "        sequences.append((seq, label))\n",
    "    return sequences\n",
    "\n",
    "sequence_length = 30  # Example sequence length, adjust as needed\n",
    "train_sequences = create_sequences(features_scaled, target.values, sequence_length)\n",
    "test_sequences = create_sequences(test_features_scaled, test_target.values, sequence_length)\n",
    "\n",
    "# Create DataLoader for LSTM\n",
    "batch_size = 64  # Adjust as needed\n",
    "\n",
    "train_dataset = TensorDataset(\n",
    "    torch.tensor([seq for seq, label in train_sequences], dtype=torch.float32),\n",
    "    torch.tensor([label for seq, label in train_sequences], dtype=torch.float32)\n",
    ")\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(\n",
    "    torch.tensor([seq for seq, label in test_sequences], dtype=torch.float32),\n",
    "    torch.tensor([label for seq, label in test_sequences], dtype=torch.float32)\n",
    ")\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to sequences for LSTM\n",
    "def create_sequences(data, target, sequence_length):\n",
    "    sequences = []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        seq = data[i:i+sequence_length]\n",
    "        label = target[i+sequence_length]\n",
    "        sequences.append((seq, label))\n",
    "    return sequences\n",
    "\n",
    "sequence_length = 30  # Example sequence length, adjust as needed\n",
    "train_sequences = create_sequences(features_scaled, target.values, sequence_length)\n",
    "test_sequences = create_sequences(test_features_scaled, test_target.values, sequence_length)\n",
    "\n",
    "# Create DataLoader for LSTM\n",
    "batch_size = 64  # Adjust as needed\n",
    "\n",
    "train_dataset = TensorDataset(\n",
    "    torch.tensor([seq for seq, label in train_sequences], dtype=torch.float32),\n",
    "    torch.tensor([label for seq, label in train_sequences], dtype=torch.float32)\n",
    ")\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(\n",
    "    torch.tensor([seq for seq, label in test_sequences], dtype=torch.float32),\n",
    "    torch.tensor([label for seq, label in test_sequences], dtype=torch.float32)\n",
    ")\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LSTM Model\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(x.device)\n",
    "        \n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "input_dim = features_scaled.shape[1]\n",
    "hidden_dim = 64  # Adjust as needed\n",
    "output_dim = 1\n",
    "num_layers = 2  # Adjust as needed\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "lstm_model = LSTMModel(input_dim, hidden_dim, output_dim, num_layers).to(device)\n",
    "\n",
    "# Train the LSTM Model\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(lstm_model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 50  # Adjust as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prasad/.local/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/prasad/.local/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([12])) that is different to the input size (torch.Size([12, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 6.4374\n",
      "Epoch [2/50], Loss: 12.3474\n",
      "Epoch [3/50], Loss: 20.5484\n",
      "Epoch [4/50], Loss: 7.6913\n",
      "Epoch [5/50], Loss: 1.8755\n",
      "Epoch [6/50], Loss: 3.0957\n",
      "Epoch [7/50], Loss: 4.1674\n",
      "Epoch [8/50], Loss: 5.2920\n",
      "Epoch [9/50], Loss: 1.7676\n",
      "Epoch [10/50], Loss: 2.9145\n",
      "Epoch [11/50], Loss: 2.0051\n",
      "Epoch [12/50], Loss: 3.4016\n",
      "Epoch [13/50], Loss: 5.4867\n",
      "Epoch [14/50], Loss: 4.0051\n",
      "Epoch [15/50], Loss: 24.6307\n",
      "Epoch [16/50], Loss: 6.2062\n",
      "Epoch [17/50], Loss: 17.0922\n",
      "Epoch [18/50], Loss: 7.2158\n",
      "Epoch [19/50], Loss: 4.7858\n",
      "Epoch [20/50], Loss: 2.1628\n",
      "Epoch [21/50], Loss: 13.4443\n",
      "Epoch [22/50], Loss: 32.3025\n",
      "Epoch [23/50], Loss: 1.9311\n",
      "Epoch [24/50], Loss: 4.2973\n",
      "Epoch [25/50], Loss: 6.9391\n",
      "Epoch [26/50], Loss: 21.7714\n",
      "Epoch [27/50], Loss: 4.8362\n",
      "Epoch [28/50], Loss: 25.7907\n",
      "Epoch [29/50], Loss: 90.8811\n",
      "Epoch [30/50], Loss: 34.8026\n",
      "Epoch [31/50], Loss: 14.7798\n",
      "Epoch [32/50], Loss: 6.2255\n",
      "Epoch [33/50], Loss: 8.2572\n",
      "Epoch [34/50], Loss: 6.7291\n",
      "Epoch [35/50], Loss: 6.7018\n",
      "Epoch [36/50], Loss: 2.1545\n",
      "Epoch [37/50], Loss: 12.9209\n",
      "Epoch [38/50], Loss: 1.6279\n",
      "Epoch [39/50], Loss: 3.5435\n",
      "Epoch [40/50], Loss: 13.0298\n",
      "Epoch [41/50], Loss: 28.6729\n",
      "Epoch [42/50], Loss: 4.0259\n",
      "Epoch [43/50], Loss: 2.4311\n",
      "Epoch [44/50], Loss: 2.1681\n",
      "Epoch [45/50], Loss: 10.7957\n",
      "Epoch [46/50], Loss: 5.1213\n",
      "Epoch [47/50], Loss: 13.0879\n",
      "Epoch [48/50], Loss: 2.9757\n",
      "Epoch [49/50], Loss: 4.5761\n",
      "Epoch [50/50], Loss: 2.1252\n"
     ]
    }
   ],
   "source": [
    "lstm_model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for sequences, labels in train_loader:\n",
    "        sequences, labels = sequences.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = lstm_model(sequences)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Model       MAE       MSE      RMSE       R2\n",
      "0  LSTM  5.833561  39.73175  6.303313 -1.19339\n",
      "  Model  Accuracy  Precision  Recall  F1 Score\n",
      "0  LSTM   0.93725        0.0     0.0       0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prasad/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the models\n",
    "def evaluate_model(predictions, true_values):\n",
    "    mae = mean_absolute_error(true_values, predictions)\n",
    "    mse = mean_squared_error(true_values, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(true_values, predictions)\n",
    "    return mae, mse, rmse, r2\n",
    "\n",
    "\n",
    "# Evaluate the LSTM Model\n",
    "lstm_model.eval()\n",
    "lstm_predictions = []\n",
    "lstm_true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sequences, labels in test_loader:\n",
    "        sequences, labels = sequences.to(device), labels.to(device)\n",
    "        \n",
    "        outputs = lstm_model(sequences)\n",
    "        lstm_predictions.extend(outputs.cpu().numpy())\n",
    "        lstm_true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Inverse transform the LSTM predictions to the original scale\n",
    "lstm_predictions_original = np.array(lstm_predictions) * scaler.scale_[features.columns.get_loc('PRCP_LAG_1')] + scaler.mean_[features.columns.get_loc('PRCP_LAG_1')]\n",
    "\n",
    "# Calculate evaluation metrics for LSTM\n",
    "lstm_mae = mean_absolute_error(lstm_true_labels, lstm_predictions_original)\n",
    "lstm_mse = mean_squared_error(lstm_true_labels, lstm_predictions_original)\n",
    "lstm_rmse = np.sqrt(lstm_mse)\n",
    "lstm_r2 = r2_score(lstm_true_labels, lstm_predictions_original)\n",
    "\n",
    "lstm_evaluation = (lstm_mae, lstm_mse, lstm_rmse, lstm_r2)\n",
    "\n",
    "# Compile the evaluation results into a DataFrame\n",
    "evaluation_results = pd.DataFrame({\n",
    "    'Model': ['LSTM'],\n",
    "    'MAE': [lstm_evaluation[0]],\n",
    "    'MSE': [lstm_evaluation[1]],\n",
    "    'RMSE': [lstm_evaluation[2]],\n",
    "    'R2': [lstm_evaluation[3]]\n",
    "})\n",
    "\n",
    "print(evaluation_results)\n",
    "\n",
    "# Predict the occurrence of precipitation events > 10 mm/day\n",
    "threshold = 10  # mm/day\n",
    "lstm_classification = (lstm_predictions_original > threshold).astype(int)\n",
    "\n",
    "# Adjust true_classification to match the length of LSTM predictions\n",
    "true_classification_adjusted = (test_target.values[sequence_length:] > threshold).astype(int)\n",
    "\n",
    "# Evaluate classification metrics\n",
    "def evaluate_classification(predictions, true_values):\n",
    "    accuracy = accuracy_score(true_values, predictions)\n",
    "    precision = precision_score(true_values, predictions)\n",
    "    recall = recall_score(true_values, predictions)\n",
    "    f1 = f1_score(true_values, predictions)\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# Perform classification on the cross-validated predictions\n",
    "classification_threshold = 10  # mm/day\n",
    "\n",
    "classification_results = []\n",
    "true_classification = (test_target > threshold).astype(int)\n",
    "\n",
    "\n",
    "lstm_classification_metrics = evaluate_classification(lstm_classification, true_classification_adjusted)\n",
    "\n",
    "# Compile the classification evaluation results into a DataFrame\n",
    "classification_results = pd.DataFrame({\n",
    "    'Model': ['LSTM'],\n",
    "    'Accuracy': [lstm_classification_metrics[0]],\n",
    "    'Precision': [lstm_classification_metrics[1]],\n",
    "    'Recall': [lstm_classification_metrics[2]],\n",
    "    'F1 Score': [lstm_classification_metrics[3]]\n",
    "})\n",
    "\n",
    "print(classification_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation 2: Using Time based Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prasad/.local/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/prasad/.local/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([23])) that is different to the input size (torch.Size([23, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/prasad/.local/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/prasad/.local/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([57])) that is different to the input size (torch.Size([57, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/prasad/.local/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([42])) that is different to the input size (torch.Size([42, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/prasad/.local/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([27])) that is different to the input size (torch.Size([27, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression Results:\n",
      "  Model       MAE        MSE      RMSE        R2\n",
      "0  LSTM  5.867324  40.318371  6.349675 -2.053693\n"
     ]
    }
   ],
   "source": [
    "# Time-based cross-validation\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "regression_cv_predictions = {}\n",
    "regression_results = []\n",
    "\n",
    "lstm_predictions = []\n",
    "lstm_true_values = []\n",
    "\n",
    "for train_index, test_index in tscv.split(features_scaled):\n",
    "    X_train, X_test = features_scaled[train_index], features_scaled[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    train_sequences = create_sequences(X_train, y_train.values, sequence_length)\n",
    "    test_sequences = create_sequences(X_test, y_test.values, sequence_length)\n",
    "    \n",
    "    train_dataset = TensorDataset(\n",
    "        torch.tensor([seq for seq, label in train_sequences], dtype=torch.float32),\n",
    "        torch.tensor([label for seq, label in train_sequences], dtype=torch.float32)\n",
    "    )\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    test_dataset = TensorDataset(\n",
    "        torch.tensor([seq for seq, label in test_sequences], dtype=torch.float32),\n",
    "        torch.tensor([label for seq, label in test_sequences], dtype=torch.float32)\n",
    "    )\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    lstm_model = LSTMModel(input_dim, hidden_dim, output_dim, num_layers).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(lstm_model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Train the LSTM model\n",
    "    lstm_model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for sequences, labels in train_loader:\n",
    "            sequences, labels = sequences.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = lstm_model(sequences)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    # Evaluate the LSTM model\n",
    "    lstm_model.eval()\n",
    "    with torch.no_grad():\n",
    "        for sequences, labels in test_loader:\n",
    "            sequences, labels = sequences.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = lstm_model(sequences)\n",
    "            lstm_predictions.extend(outputs.cpu().numpy())\n",
    "            lstm_true_values.extend(labels.cpu().numpy())\n",
    "\n",
    "# Inverse transform the LSTM predictions to the original scale\n",
    "lstm_predictions_original = np.array(lstm_predictions) * scaler.scale_[features.columns.get_loc('PRCP_LAG_1')] + scaler.mean_[features.columns.get_loc('PRCP_LAG_1')]\n",
    "\n",
    "# Evaluate LSTM regression metrics\n",
    "lstm_mae = mean_absolute_error(lstm_true_values, lstm_predictions_original)\n",
    "lstm_mse = mean_squared_error(lstm_true_values, lstm_predictions_original)\n",
    "lstm_rmse = np.sqrt(lstm_mse)\n",
    "lstm_r2 = r2_score(lstm_true_values, lstm_predictions_original)\n",
    "\n",
    "regression_results.append({\n",
    "    'Model': 'LSTM',\n",
    "    'MAE': lstm_mae,\n",
    "    'MSE': lstm_mse,\n",
    "    'RMSE': lstm_rmse,\n",
    "    'R2': lstm_r2\n",
    "})\n",
    "\n",
    "regression_results_df = pd.DataFrame(regression_results)\n",
    "print(\"Regression Results:\")\n",
    "print(regression_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Results:\n",
      "  Model  Accuracy  Precision  Recall  F1 Score\n",
      "0  LSTM  0.969192        0.0     0.0       0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prasad/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Perform classification on the cross-validated predictions\n",
    "classification_threshold = 10  # mm/day\n",
    "\n",
    "classification_results = []\n",
    "\n",
    "for model_name, predictions_original in regression_cv_predictions.items():\n",
    "    true_classification_adjusted = (np.array(true_values[:len(predictions_original)]) > classification_threshold).astype(int)\n",
    "    classification_predictions = (predictions_original > classification_threshold).astype(int)\n",
    "\n",
    "    # Ensure lengths are consistent\n",
    "    assert len(true_classification_adjusted) == len(classification_predictions), f\"Length mismatch for {model_name}: {len(true_classification_adjusted)} != {len(classification_predictions)}\"\n",
    "\n",
    "    # Evaluate classification metrics\n",
    "    accuracy = accuracy_score(true_classification_adjusted, classification_predictions)\n",
    "    precision = precision_score(true_classification_adjusted, classification_predictions)\n",
    "    recall = recall_score(true_classification_adjusted, classification_predictions)\n",
    "    f1 = f1_score(true_classification_adjusted, classification_predictions)\n",
    "    \n",
    "    classification_results.append({\n",
    "        'Model': model_name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1\n",
    "    })\n",
    "\n",
    "# Adjust true_classification for LSTM predictions\n",
    "true_classification_adjusted_lstm = (np.array(lstm_true_values) > classification_threshold).astype(int)\n",
    "lstm_classification_predictions = (lstm_predictions_original > classification_threshold).astype(int)\n",
    "\n",
    "# Ensure lengths are consistent\n",
    "assert len(true_classification_adjusted_lstm) == len(lstm_classification_predictions), f\"Length mismatch for LSTM: {len(true_classification_adjusted_lstm)} != {len(lstm_classification_predictions)}\"\n",
    "\n",
    "# Evaluate LSTM classification metrics\n",
    "lstm_accuracy = accuracy_score(true_classification_adjusted_lstm, lstm_classification_predictions)\n",
    "lstm_precision = precision_score(true_classification_adjusted_lstm, lstm_classification_predictions)\n",
    "lstm_recall = recall_score(true_classification_adjusted_lstm, lstm_classification_predictions)\n",
    "lstm_f1 = f1_score(true_classification_adjusted_lstm, lstm_classification_predictions)\n",
    "\n",
    "classification_results.append({\n",
    "    'Model': 'LSTM',\n",
    "    'Accuracy': lstm_accuracy,\n",
    "    'Precision': lstm_precision,\n",
    "    'Recall': lstm_recall,\n",
    "    'F1 Score': lstm_f1\n",
    "})\n",
    "\n",
    "classification_results_df = pd.DataFrame(classification_results)\n",
    "print(\"Classification Results:\")\n",
    "print(classification_results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
